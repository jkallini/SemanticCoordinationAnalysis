{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCA Analysis\n",
    "(We might skip this for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunctions under analysis\n",
    "CONJUNCTIONS = ['and', 'or', 'but', 'nor']\n",
    "\n",
    "# Categories under analysis\n",
    "NOUN_CATEGORIES = ['NN', 'NNS', 'NNP', 'NNPS', 'NP', 'NX']\n",
    "VERB_CATEGORIES = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'VP']\n",
    "ADJ_CATEGORIES = ['JJ', 'JJR', 'JJS', 'ADJP']\n",
    "ADV_CATEGORIES = ['RB', 'RBR', 'RBS', 'ADVP']\n",
    "\n",
    "PHRASAL_CATEGORIES = ['NP', 'VP', 'ADJP', 'ADVP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV file with coordination samples\n",
    "samples = pd.read_csv(\"csv/COCA/samples.csv\", index_col=None, header=0)\n",
    "\n",
    "# Load CSV files with raters' judgments\n",
    "rater1 = pd.read_csv(\"csv/COCA/raters/rater1.csv\", index_col=None, header=0)\n",
    "rater2 = pd.read_csv(\"csv/COCA/raters/rater2.csv\", index_col=None, header=0)\n",
    "rater3 = pd.read_csv(\"csv/COCA/raters/rater3.csv\", index_col=None, header=0)\n",
    "\n",
    "# Take majority of three raters' judgments\n",
    "r1 = rater1['Correct?']\n",
    "r2 = rater2['Correct?']\n",
    "r3 = rater3['Correct?']\n",
    "samples['Correct? (Majority)'] = r1 & r2 & r3\n",
    "correct = samples[samples['Correct? (Majority)']]\n",
    "correct.to_csv('csv/COCA/correct_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# likes = utils.likes_df(correct)\n",
    "# unlikes = utils.unlikes_df(correct)\n",
    "\n",
    "# likes = utils.filter_conj_length(likes, 5)\n",
    "# unlikes = utils.filter_conj_length(unlikes, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.add_conj_heads(likes)\n",
    "# utils.add_conj_heads(unlikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# likes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PTB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load samples from PTB\n",
    "ptb_samples = pd.read_csv(\"csv/PTB/PTB_ccps.csv\", index_col=None, header=0)\n",
    "\n",
    "# Get like coordinations\n",
    "ptb_likes = utils.likes_df(ptb_samples)\n",
    "\n",
    "# Filter coordinations so that each conjunct is only one word\n",
    "ptb_likes = utils.filter_conj_length(ptb_likes, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4061\n",
      "699\n",
      "3362\n",
      "3362\n",
      "457\n"
     ]
    }
   ],
   "source": [
    "# Add conjunct head columns for wordnet analysis\n",
    "# We can do this since each conjunct is only one word long\n",
    "ptb_likes['1st Conjunct Head'] = ptb_likes['1st Conjunct Text']\n",
    "ptb_likes['2nd Conjunct Head'] = ptb_likes['2nd Conjunct Text']\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Finding closures over wordnet relations produces redundant search warnings\n",
    "# We'll just filter these warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    # Get wordnet relations for like coordinations from PTB\n",
    "    ptb_synonyms = utils.analyze_synonymy(ptb_likes)\n",
    "    ptb_antonyms = utils.analyze_antonymy(ptb_likes)\n",
    "    ptb_hypernyms = utils.analyze_hypernymy(ptb_likes)\n",
    "    ptb_cohyponyms = utils.analyze_cohyponymy(ptb_likes)\n",
    "    ptb_entailments = utils.analyze_entailment(ptb_likes)\n",
    "\n",
    "print(len(ptb_synonyms))\n",
    "print(len(ptb_antonyms))\n",
    "print(len(ptb_hypernyms))\n",
    "print(len(ptb_cohyponyms))\n",
    "print(len(ptb_entailments))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "90d1250365b552bac7bd3e3505e64c228a1a6f7c9121581557d7a3f6f706e389"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
